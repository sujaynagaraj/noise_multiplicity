{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "numeric-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from src.models import *\n",
    "from src.loss_functions import *\n",
    "from src.noise import *\n",
    "from src.metrics import *\n",
    "from src.plotting import *\n",
    "from src.generate_data import *\n",
    "from src.real_data import *\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "from operator import xor\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fabulous-machinery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6313169fd58450396be44bfd7902c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing cshock_eicu - LR - noisy_train_loss: 'noise'\n",
      "Error processing cshock_eicu - LR - clean_test_loss: 'noise'\n",
      "Error processing cshock_eicu - LR - clean_test_acc: 'noise'\n",
      "Error processing cshock_eicu - LR - train_loss: 'noise'\n",
      "Error processing cshock_eicu - LR - train_acc: 'noise'\n",
      "Error processing cshock_eicu - LR - test_loss: 'noise'\n",
      "Error processing cshock_eicu - LR - test_acc: 'noise'\n",
      "Error processing cshock_eicu - LR - regret_test: 'Loss Function'\n",
      "Error processing cshock_eicu - LR - regret_test: 'Loss Function'\n",
      "Error processing cshock_eicu - LR - disagreement_test: 'Loss Function'\n",
      "Error processing cshock_eicu - LR - disagreement_test: 'Loss Function'\n",
      "Error processing cshock_eicu - NN - noisy_train_loss: 'noise'\n",
      "Error processing cshock_eicu - NN - clean_test_loss: 'noise'\n",
      "Error processing cshock_eicu - NN - clean_test_acc: 'noise'\n",
      "Error processing cshock_eicu - NN - train_loss: 'noise'\n",
      "Error processing cshock_eicu - NN - train_acc: 'noise'\n",
      "Error processing cshock_eicu - NN - test_loss: 'noise'\n",
      "Error processing cshock_eicu - NN - test_acc: 'noise'\n",
      "Error processing cshock_eicu - NN - regret_test: 'Loss Function'\n",
      "Error processing cshock_eicu - NN - regret_test: 'Loss Function'\n",
      "Error processing cshock_eicu - NN - disagreement_test: 'Loss Function'\n",
      "Error processing cshock_eicu - NN - disagreement_test: 'Loss Function'\n",
      "Error processing cshock_mimic - LR - noisy_train_loss: 'noise'\n",
      "Error processing cshock_mimic - LR - clean_test_loss: 'noise'\n",
      "Error processing cshock_mimic - LR - clean_test_acc: 'noise'\n",
      "Error processing cshock_mimic - LR - train_loss: 'noise'\n",
      "Error processing cshock_mimic - LR - train_acc: 'noise'\n",
      "Error processing cshock_mimic - LR - test_loss: 'noise'\n",
      "Error processing cshock_mimic - LR - test_acc: 'noise'\n",
      "Error processing cshock_mimic - LR - regret_test: 'Loss Function'\n",
      "Error processing cshock_mimic - LR - regret_test: 'Loss Function'\n",
      "Error processing cshock_mimic - LR - disagreement_test: 'Loss Function'\n",
      "Error processing cshock_mimic - LR - disagreement_test: 'Loss Function'\n",
      "Error processing cshock_mimic - NN - noisy_train_loss: 'noise'\n",
      "Error processing cshock_mimic - NN - clean_test_loss: 'noise'\n",
      "Error processing cshock_mimic - NN - clean_test_acc: 'noise'\n",
      "Error processing cshock_mimic - NN - train_loss: 'noise'\n",
      "Error processing cshock_mimic - NN - train_acc: 'noise'\n",
      "Error processing cshock_mimic - NN - test_loss: 'noise'\n",
      "Error processing cshock_mimic - NN - test_acc: 'noise'\n",
      "Error processing cshock_mimic - NN - regret_test: 'Loss Function'\n",
      "Error processing cshock_mimic - NN - regret_test: 'Loss Function'\n",
      "Error processing cshock_mimic - NN - disagreement_test: 'Loss Function'\n",
      "Error processing cshock_mimic - NN - disagreement_test: 'Loss Function'\n",
      "Error processing saps - LR - noisy_train_loss: 'noise'\n",
      "Error processing saps - LR - clean_test_loss: 'noise'\n",
      "Error processing saps - LR - clean_test_acc: 'noise'\n",
      "Error processing saps - LR - train_loss: 'noise'\n",
      "Error processing saps - LR - train_acc: 'noise'\n",
      "Error processing saps - LR - test_loss: 'noise'\n",
      "Error processing saps - LR - test_acc: 'noise'\n",
      "Error processing saps - LR - regret_test: 'Loss Function'\n",
      "Error processing saps - LR - regret_test: 'Loss Function'\n",
      "Error processing saps - LR - disagreement_test: 'Loss Function'\n",
      "Error processing saps - LR - disagreement_test: 'Loss Function'\n",
      "Error processing saps - NN - noisy_train_loss: 'noise'\n",
      "Error processing saps - NN - clean_test_loss: 'noise'\n",
      "Error processing saps - NN - clean_test_acc: 'noise'\n",
      "Error processing saps - NN - train_loss: 'noise'\n",
      "Error processing saps - NN - train_acc: 'noise'\n",
      "Error processing saps - NN - test_loss: 'noise'\n",
      "Error processing saps - NN - test_acc: 'noise'\n",
      "Error processing saps - NN - regret_test: 'Loss Function'\n",
      "Error processing saps - NN - regret_test: 'Loss Function'\n",
      "Error processing saps - NN - disagreement_test: 'Loss Function'\n",
      "Error processing saps - NN - disagreement_test: 'Loss Function'\n",
      "Error processing support - LR - noisy_train_loss: 'noise'\n",
      "Error processing support - LR - clean_test_loss: 'noise'\n",
      "Error processing support - LR - clean_test_acc: 'noise'\n",
      "Error processing support - LR - train_loss: 'noise'\n",
      "Error processing support - LR - train_acc: 'noise'\n",
      "Error processing support - LR - test_loss: 'noise'\n",
      "Error processing support - LR - test_acc: 'noise'\n",
      "Error processing support - LR - regret_test: 'Loss Function'\n",
      "Error processing support - LR - regret_test: 'Loss Function'\n",
      "Error processing support - LR - disagreement_test: 'Loss Function'\n",
      "Error processing support - LR - disagreement_test: 'Loss Function'\n",
      "Error processing support - NN - noisy_train_loss: 'noise'\n",
      "Error processing support - NN - clean_test_loss: 'noise'\n",
      "Error processing support - NN - clean_test_acc: 'noise'\n",
      "Error processing support - NN - train_loss: 'noise'\n",
      "Error processing support - NN - train_acc: 'noise'\n",
      "Error processing support - NN - test_loss: 'noise'\n",
      "Error processing support - NN - test_acc: 'noise'\n",
      "Error processing support - NN - regret_test: 'Loss Function'\n",
      "Error processing support - NN - regret_test: 'Loss Function'\n",
      "Error processing support - NN - disagreement_test: 'Loss Function'\n",
      "Error processing support - NN - disagreement_test: 'Loss Function'\n",
      "Error processing lungcancer - LR - noisy_train_loss: 'noise'\n",
      "Error processing lungcancer - LR - clean_test_loss: 'noise'\n",
      "Error processing lungcancer - LR - clean_test_acc: 'noise'\n",
      "Error processing lungcancer - LR - train_loss: 'noise'\n",
      "Error processing lungcancer - LR - train_acc: 'noise'\n",
      "Error processing lungcancer - LR - test_loss: 'noise'\n",
      "Error processing lungcancer - LR - test_acc: 'noise'\n",
      "Error processing lungcancer - LR - regret_test: 'Loss Function'\n",
      "Error processing lungcancer - LR - regret_test: 'Loss Function'\n",
      "Error processing lungcancer - LR - disagreement_test: 'Loss Function'\n",
      "Error processing lungcancer - LR - disagreement_test: 'Loss Function'\n",
      "Error processing lungcancer - NN - noisy_train_loss: 'noise'\n",
      "Error processing lungcancer - NN - clean_test_loss: 'noise'\n",
      "Error processing lungcancer - NN - clean_test_acc: 'noise'\n",
      "Error processing lungcancer - NN - train_loss: 'noise'\n",
      "Error processing lungcancer - NN - train_acc: 'noise'\n",
      "Error processing lungcancer - NN - test_loss: 'noise'\n",
      "Error processing lungcancer - NN - test_acc: 'noise'\n",
      "Error processing lungcancer - NN - regret_test: 'Loss Function'\n",
      "Error processing lungcancer - NN - regret_test: 'Loss Function'\n",
      "Error processing lungcancer - NN - disagreement_test: 'Loss Function'\n",
      "Error processing lungcancer - NN - disagreement_test: 'Loss Function'\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the percentage of rates greater than 25\n",
    "def threshold(x):\n",
    "    return (x > 25).mean() * 100\n",
    "\n",
    "# Function to calculate the percentage of rates = 0\n",
    "def no_regret(x):\n",
    "    return (x == 0).mean() * 100\n",
    "\n",
    "# Define model types and datasets\n",
    "model_types = [\"LR\", \"NN\"]\n",
    "datasets = [\"cshock_eicu\", \"cshock_mimic\", \"saps\", \"support\", \"lungcancer\"]\n",
    "population_metrics = ['noisy_train_loss', 'clean_test_loss', 'clean_test_acc']\n",
    "individual_metrics = ['regret_test', 'disagreement_test']\n",
    "our_metrics = [\"train_loss\", \"train_acc\", 'test_loss', \"test_acc\"]\n",
    "\n",
    "uncertainty_type = \"forward\"\n",
    "noise_type = \"class_independent\"\n",
    "epsilon = 0.1\n",
    "fixed_class = 0\n",
    "fixed_noise = 0\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Iterate over datasets and model types\n",
    "for dataset in tqdm(datasets):\n",
    "    for model_type in model_types:\n",
    "        for noise_type in [\"class_independent\", \"class_conditional\"]:\n",
    "            for metric in population_metrics:\n",
    "                try:\n",
    "                    # Load metrics data\n",
    "                    metrics_df = load_metrics(model_type, noise_type, \"forward\", metric=metric, dataset=dataset, fixed_class=fixed_class, fixed_noise=fixed_noise, epsilon=epsilon)\n",
    "\n",
    "                    # Rename 'Rate (%)' column to 'value'\n",
    "                    metrics_df.rename(columns={'Rate (%)': 'value', 'Noise Level (%)': \"noise\", \"Loss Function\": \"method_name\", \"Metric\":\"metric\"}, inplace=True)\n",
    "\n",
    "                    # Add Draw_id as the index of each sub DataFrame\n",
    "                    metrics_df['draw_id'] = metrics_df.index\n",
    "\n",
    "                    # Add additional columns\n",
    "                    metrics_df['dataset'] = dataset\n",
    "                    metrics_df['model_class'] = model_type\n",
    "                    metrics_df['noise_type'] = noise_type\n",
    "                    metrics_df['noise'] = metrics_df['noise'] / 100\n",
    "\n",
    "                    if \"acc\" in metric:\n",
    "                        metrics_df['value'] = metrics_df['value'] / 100\n",
    "\n",
    "                    # Append the modified DataFrame to the list\n",
    "                    dfs.append(metrics_df)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {dataset} - {noise_type} - {model_type} - {metric}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            for m in our_metrics:\n",
    "                try:\n",
    "                    # Load metrics data\n",
    "                    metrics_df = load_metrics(model_type, noise_type, \"backward\", metric=m, dataset=dataset, fixed_class=fixed_class, fixed_noise=fixed_noise, epsilon=epsilon)\n",
    "\n",
    "                    # Rename 'Rate (%)' column to 'value'\n",
    "                    metrics_df.rename(columns={'Rate (%)': 'value', 'Noise Level (%)': \"noise\", \"Loss Function\": \"method_name\", \"Metric\":\"metric\"}, inplace=True)\n",
    "\n",
    "                    # Add Draw_id as the index of each sub DataFrame\n",
    "                    metrics_df['draw_id'] = metrics_df.index\n",
    "\n",
    "                    # Add additional columns\n",
    "                    metrics_df['method_name'] = \"ours\"\n",
    "                    metrics_df['dataset'] = dataset\n",
    "                    metrics_df['model_class'] = model_type\n",
    "                    metrics_df['noise_type'] = noise_type\n",
    "                    metrics_df['noise'] = metrics_df['noise'] / 100\n",
    "\n",
    "                    if \"acc\" in m:\n",
    "                        metrics_df['value'] = metrics_df['value'] / 100\n",
    "\n",
    "                    # Rename metric columns if needed\n",
    "                    if m == 'test_loss':\n",
    "                        m = 'clean_test_loss'\n",
    "                    elif m == 'test_acc':\n",
    "                        m = 'clean_test_acc'\n",
    "\n",
    "                    # Append the modified DataFrame to the list\n",
    "                    metrics_df['metric'] = m  # Adding the metric name as a column\n",
    "                    dfs.append(metrics_df)\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {dataset} - {noise_type} - {model_type} - {m}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            for m in individual_metrics:\n",
    "\n",
    "                for uncertainty in [\"forward\", \"backward\"]:\n",
    "                    try:\n",
    "                        # Load metrics data\n",
    "                        metrics_df = load_metrics(model_type, noise_type, uncertainty, metric=m, dataset=dataset, fixed_class=fixed_class, fixed_noise=fixed_noise, epsilon=epsilon)\n",
    "\n",
    "\n",
    "                                # Grouping by 'Loss Function' and 'Noise Level' and calculating statistics\n",
    "                        summary_stats = metrics_df.groupby(['Loss Function', 'Noise Level (%)'])['Rate (%)'].agg([\n",
    "                            'min', 'max', 'mean', 'std',\n",
    "                            ('Percentage Over 25%', threshold),\n",
    "                            ('Stable', no_regret)# Custom aggregation function\n",
    "                        ]).reset_index()\n",
    "\n",
    "                        # Renaming columns for clarity (optional as names are automatically set by the tuple)\n",
    "                        summary_stats.columns = ['method_name', 'noise', m+'_min', m+'_max', m+'_mean', m+'_std', m+'_25', m+'_stable']\n",
    "\n",
    "                        df_pivoted = summary_stats.melt(id_vars=['method_name', 'noise'], var_name='metric', value_name='value')\n",
    "\n",
    "                        if uncertainty == \"backward\":\n",
    "                            df_pivoted[\"method_name\"] = \"ours\"\n",
    "\n",
    "                        df_pivoted[\"dataset\"] = dataset\n",
    "                        df_pivoted[\"noise\"] = df_pivoted[\"noise\"]/100\n",
    "                        df_pivoted[\"model_class\"] = model_type\n",
    "                        df_pivoted[\"noise_type\"] = noise_type\n",
    "                        df_pivoted[\"value\"] = df_pivoted[\"value\"]/100\n",
    "\n",
    "                        # Append the modified DataFrame to the list\n",
    "                        dfs.append(df_pivoted)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {dataset} - {noise_type} -  {model_type} - {m}: {e}\")\n",
    "                        continue\n",
    "\n",
    "            \n",
    "                \n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "patient-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>noise</th>\n",
       "      <th>value</th>\n",
       "      <th>method_name</th>\n",
       "      <th>Index</th>\n",
       "      <th>draw_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_class</th>\n",
       "      <th>noise_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noisy_train_loss</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>BCE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cshock_eicu</td>\n",
       "      <td>LR</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noisy_train_loss</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>BCE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cshock_eicu</td>\n",
       "      <td>LR</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noisy_train_loss</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>BCE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cshock_eicu</td>\n",
       "      <td>LR</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noisy_train_loss</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>BCE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cshock_eicu</td>\n",
       "      <td>LR</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noisy_train_loss</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.479459</td>\n",
       "      <td>BCE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>cshock_eicu</td>\n",
       "      <td>LR</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544555</th>\n",
       "      <td>disagreement_test_stable</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.989828</td>\n",
       "      <td>ours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lungcancer</td>\n",
       "      <td>NN</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544556</th>\n",
       "      <td>disagreement_test_stable</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.968055</td>\n",
       "      <td>ours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lungcancer</td>\n",
       "      <td>NN</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544557</th>\n",
       "      <td>disagreement_test_stable</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.931739</td>\n",
       "      <td>ours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lungcancer</td>\n",
       "      <td>NN</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544558</th>\n",
       "      <td>disagreement_test_stable</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.794978</td>\n",
       "      <td>ours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lungcancer</td>\n",
       "      <td>NN</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544559</th>\n",
       "      <td>disagreement_test_stable</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lungcancer</td>\n",
       "      <td>NN</td>\n",
       "      <td>class_independent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544560 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          metric  noise     value method_name  Index  draw_id  \\\n",
       "0               noisy_train_loss   0.00  0.479459         BCE    0.0      0.0   \n",
       "1               noisy_train_loss   0.00  0.479459         BCE    1.0      1.0   \n",
       "2               noisy_train_loss   0.00  0.479459         BCE    2.0      2.0   \n",
       "3               noisy_train_loss   0.00  0.479459         BCE    3.0      3.0   \n",
       "4               noisy_train_loss   0.00  0.479459         BCE    4.0      4.0   \n",
       "...                          ...    ...       ...         ...    ...      ...   \n",
       "544555  disagreement_test_stable   0.01  0.989828        ours    NaN      NaN   \n",
       "544556  disagreement_test_stable   0.05  0.968055        ours    NaN      NaN   \n",
       "544557  disagreement_test_stable   0.10  0.931739        ours    NaN      NaN   \n",
       "544558  disagreement_test_stable   0.20  0.794978        ours    NaN      NaN   \n",
       "544559  disagreement_test_stable   0.40  0.000000        ours    NaN      NaN   \n",
       "\n",
       "            dataset model_class         noise_type  \n",
       "0       cshock_eicu          LR  class_independent  \n",
       "1       cshock_eicu          LR  class_independent  \n",
       "2       cshock_eicu          LR  class_independent  \n",
       "3       cshock_eicu          LR  class_independent  \n",
       "4       cshock_eicu          LR  class_independent  \n",
       "...             ...         ...                ...  \n",
       "544555   lungcancer          NN  class_independent  \n",
       "544556   lungcancer          NN  class_independent  \n",
       "544557   lungcancer          NN  class_independent  \n",
       "544558   lungcancer          NN  class_independent  \n",
       "544559   lungcancer          NN  class_independent  \n",
       "\n",
       "[544560 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hourly-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rename_metric(metric):\n",
    "#     parts = metric.split('_')\n",
    "    \n",
    "#     if len(parts)==4:\n",
    "#         return f\"{parts[0]}_{parts[2]}_{parts[1]}_{parts[3]}\"\n",
    "        \n",
    "#     if len(parts)==3 and (\"disagreement\" not in metric and \"regret\" not in metric):\n",
    "#         return f\"{parts[1]}_{parts[0]}_{parts[2]}\"\n",
    "#     else:\n",
    "#         return metric\n",
    "        \n",
    "    \n",
    "# test_df = final_df.copy()\n",
    "# # Apply the rename_metric function to the metric column\n",
    "# test_df['metric'] = test_df['metric'].apply(lambda x: rename_metric(x))\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "statewide-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Export to CSV\n",
    "final_df.to_csv(f\"big_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "metropolitan-special",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['noisy_train_loss', 'clean_test_loss', 'clean_test_acc',\n",
       "       'train_loss', 'train_acc', 'regret_test_min', 'regret_test_max',\n",
       "       'regret_test_mean', 'regret_test_std', 'regret_test_25',\n",
       "       'regret_test_stable', 'disagreement_test_min',\n",
       "       'disagreement_test_max', 'disagreement_test_mean',\n",
       "       'disagreement_test_std', 'disagreement_test_25',\n",
       "       'disagreement_test_stable'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.metric.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-bicycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisyTS",
   "language": "python",
   "name": "noisyts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
