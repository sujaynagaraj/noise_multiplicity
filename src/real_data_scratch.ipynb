{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from src.models import *\n",
    "from src.loss_functions import *\n",
    "from src.noise import *\n",
    "from src.metrics import *\n",
    "from src.plotting import *\n",
    "from src.generate_data import *\n",
    "from src.real_data import *\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "from operator import xor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cshock_mimic\"\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = load_dataset_splits(dataset, group = \"age\")\n",
    "\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels = [0]\n",
    "noise_type = \"class_independent\"\n",
    "# noise_transition_dict = {0: np.array([[0.75,0.25],\n",
    "#                                       [0.25,0.75]]),\n",
    "#                          1: np.array([[0.75,0.25],\n",
    "#                                       [0.25,0.75]])}\n",
    "fixed_class = 1\n",
    "fixed_noise = 0.0\n",
    "\n",
    "model_type = \"NN\"\n",
    "uncertainty_type = \"forward\"\n",
    "batch_size = 512\n",
    "\n",
    "max_iter = 10000\n",
    "m = 1000\n",
    "d= X_train.shape[1]\n",
    "noise_level = 0.4\n",
    "\n",
    "\n",
    "misspecify = False\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "p_y_x_dict =  calculate_prior(y_train, noise_type = noise_type, group=group_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-trunk",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, T_true = generate_class_independent_noise(y_train, noise_level) #Fixed noise draw\n",
    "\n",
    "\n",
    "if misspecify == True: #Misspecified T\n",
    "    pass #TODO\n",
    "    T_est = None\n",
    "else: #Correct T\n",
    "    T_est = T_true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = simulate_noise_and_train_model(m, max_iter,  X_train, y_train, X_test, y_test, p_y_x_dict, T_true = T_true, T_est = T_est, noise_type = noise_type, model_type = model_type, uncertainty_type=uncertainty_type,  fixed_class=fixed_class, fixed_noise=fixed_noise, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-technology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_dicts = {\"case1\": {0: np.array([[0.8,0.2],\n",
    "                            [0.2,0.8]]),\n",
    "                1: np.array([[0.6,0.4],\n",
    "                            [0.4,0.6]])}, \n",
    "                \"case2\": { 0: np.array([[0.75,0.25],\n",
    "                                [0.25,0.75]]),\n",
    "                    1: np.array([[0.75,0.25],\n",
    "                                [0.25,0.75]])},\n",
    "                \"case3\": { 0: np.array([[0.75,0.25],\n",
    "                                [0.25,0.75]]),\n",
    "                    1: np.array([[0.75,0.25],\n",
    "                                [0.25,0.75]])},              \n",
    "                \"case4\": { 0: np.array([[0.75,0.25],\n",
    "                                [0.25,0.75]]),\n",
    "                    1: np.array([[0.75,0.25],\n",
    "                                [0.25,0.75]])}               \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case, T_dict in T_dicts.items():\n",
    "    print(case)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "serial-variance",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "simulate_noise_and_train_model() got an unexpected keyword argument 'group_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     T_est \u001b[38;5;241m=\u001b[39m T_true\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Generate error rates\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_noise_and_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m   \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43my_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mp_y_x_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mT_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mT_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mT_est\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mT_est\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgroup_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroup_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgroup_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgroup_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43muncertainty_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muncertainty_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mT_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mT_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(files_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_metrics.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# Open a file for writing in binary mode\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: simulate_noise_and_train_model() got an unexpected keyword argument 'group_train'"
     ]
    }
   ],
   "source": [
    "yn_train, T_true = generate_group_noise(y_train, group_train, T_dict)\n",
    "\n",
    "noise_type = \"group\"\n",
    "\n",
    "if uncertainty_type == \"forward\":\n",
    "    y_vec = y_train\n",
    "else: # backward\n",
    "    y_vec = yn_train\n",
    "\n",
    "if misspecify == True: #Misspecified T\n",
    "    pass #TODO\n",
    "else: #Correct T\n",
    "    T_est = T_true\n",
    "\n",
    "# Generate error rates\n",
    "metrics = simulate_noise_and_train_model(   m, \n",
    "                                            max_iter, \n",
    "                                            X_train,\n",
    "                                            y_train,\n",
    "                                            y_vec, \n",
    "                                            X_test, \n",
    "                                            y_test,\n",
    "                                            p_y_x_dict,\n",
    "                                            T_true = T_true,\n",
    "                                            T_est = T_est,\n",
    "                                            group_train = group_train,\n",
    "                                            group_test = group_test,\n",
    "                                            noise_type = noise_type, \n",
    "                                            model_type = model_type, \n",
    "                                            uncertainty_type=uncertainty_type, \n",
    "                                            T_dict = T_dict,\n",
    "                                            batch_size = batch_size)\n",
    "\n",
    "\n",
    "path = os.path.join(files_path, f\"{case}_metrics.pkl\")\n",
    "\n",
    "        # Open a file for writing in binary mode\n",
    "with open(path, 'wb') as file:\n",
    "    # Use pickle to write the dictionary to the file\n",
    "    pkl.dump(metrics, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-shareware",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisyTS",
   "language": "python",
   "name": "noisyts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
