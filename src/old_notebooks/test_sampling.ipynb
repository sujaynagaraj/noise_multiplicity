{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "western-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from src.models import *\n",
    "from src.loss_functions import *\n",
    "from src.noise import *\n",
    "from src.metrics import *\n",
    "from src.plotting import *\n",
    "from src.generate_data import *\n",
    "from src.real_data import *\n",
    "from src.real_data import Metrics, Vectors \n",
    "from src.abstain import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_curve, auc, jaccard_score\n",
    "import pandas as pd\n",
    "from supervenn import supervenn\n",
    "\n",
    "from scipy.stats import bernoulli, spearmanr\n",
    "\n",
    "from operator import xor\n",
    "\n",
    "import ast\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "sublime-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1933.75it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"cshock_eicu\"\n",
    "noise_type = \"class_conditional\"\n",
    "noise_level = 0.05\n",
    "fixed_class = 0\n",
    "fixed_noise = 0.0\n",
    "max_iter = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = load_dataset_splits(dataset, group = \"age\")\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "p_y_x_dict =  calculate_prior(y_train, noise_type = noise_type, group=group_train) #Clean prior\n",
    "\n",
    "_, T_true = generate_class_conditional_noise(y_train, noise_level, fixed_class, fixed_noise)\n",
    "\n",
    "u_vec = get_u(y_train, T = T_true, seed= 2024, noise_type = noise_type)\n",
    "yn_train = flip_labels(y_train, u_vec) #XOR\n",
    "\n",
    "noise_rates = np.where(y_train == 0, T[0, 1], T[1, 0])\n",
    "\n",
    "posterior = calculate_posterior(yn_train, T, p_y_x_dict[0])\n",
    "\n",
    "all_plausible_labels = []\n",
    "\n",
    "for seed in tqdm(range(1, max_iter+1)):\n",
    "    y_vec = yn_train\n",
    "    T= T_true\n",
    "    epsilon = 0.1\n",
    "    u_vec = infer_u(y_vec,  noise_type = noise_type, p_y_x_dict = p_y_x_dict,  T = T , seed=seed)\n",
    "\n",
    "    typical_flag, _ = is_typical(u_vec, p_y_x_dict,   T = T, y_vec = y_vec, noise_type = noise_type, uncertainty_type = \"backward\", epsilon = epsilon)\n",
    "\n",
    "    if not typical_flag:\n",
    "        continue\n",
    "\n",
    "    flipped_labels = flip_labels(y_vec, u_vec)\n",
    "    all_plausible_labels.append(flipped_labels)\n",
    "\n",
    "all_plausible_labels = np.array(all_plausible_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "governing-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "plausible_label_variation = (np.any(all_plausible_labels != all_plausible_labels[0], axis=0)).astype(int)\n",
    "susceptible_posterior = (posterior > 0).astype(int)\n",
    "susceptible =  (noise_rates > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dimensional-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition 2 met: True\n",
      "Condition 2 met: True\n",
      "Condition 3 met: True\n"
     ]
    }
   ],
   "source": [
    "# Condition 2\n",
    "# Step 1: Find indices where susceptible_posterior is 1\n",
    "indices_where_susceptible_posterior = np.where(susceptible_posterior == 1)[0]\n",
    "\n",
    "# Step 2: Check if plausible_label_variation is 1 for those indices\n",
    "all_satisfy_condition_2 = np.all(plausible_label_variation[indices_where_susceptible_posterior] == 1)\n",
    "\n",
    "print(\"Condition 2 met:\", all_satisfy_condition_2)\n",
    "# Condition 2\n",
    "# Step 1: Find indices where susceptible_posterior is 1\n",
    "indices_where_susceptible_posterior = np.where(susceptible_posterior == 1)[0]\n",
    "\n",
    "# Step 2: Check if plausible_label_variation is 1 for those indices\n",
    "all_satisfy_condition_2 = np.all(plausible_label_variation[indices_where_susceptible_posterior] == 1)\n",
    "\n",
    "print(\"Condition 2 met:\", all_satisfy_condition_2)\n",
    "\n",
    "# Condition 3\n",
    "# Step 1: Find indices where susceptible is 1 and susceptible_posterior is 0\n",
    "indices_where_susceptible_and_not_posterior = np.where((susceptible == 1) & (susceptible_posterior == 0))[0]\n",
    "\n",
    "# Step 2: Check if plausible_label_variation is 0 for those indices\n",
    "all_satisfy_condition_3 = np.all(plausible_label_variation[indices_where_susceptible_and_not_posterior] == 0)\n",
    "\n",
    "print(\"Condition 3 met:\", all_satisfy_condition_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "hungry-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any points where p(u | yn[i]) > 0 and plausible_label_variation[i] = 0: False\n"
     ]
    }
   ],
   "source": [
    "# Check if there exists any point where susceptible_posterior = 1 and plausible_label_variation = 0\n",
    "exists_posterior_variation_mismatch = np.any((susceptible_posterior == 1) & (plausible_label_variation == 0))\n",
    "\n",
    "# Output result\n",
    "print(\"Are there any points where p(u | yn[i]) > 0 and plausible_label_variation[i] = 0:\", exists_posterior_variation_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "conditional-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def get_uncertainty(m, max_iter, preds, yn_train, p_y_x_dict,group_train = None, group_test = None, noise_type=\"class_independent\", model_type=\"LR\", T=None, epsilon=0.25, misspecify=False):\n",
    "    \n",
    "    typical_count = 0\n",
    "    y_vec = yn_train\n",
    "    all_plausible_labels = []\n",
    "    \n",
    "    for seed in tqdm(range(1, max_iter+1)):\n",
    "        u_vec = infer_u(y_vec, group=group_train, noise_type=noise_type, p_y_x_dict=p_y_x_dict, T=T, seed=seed)\n",
    "        typical_flag, _ = is_typical(u_vec, p_y_x_dict, group=group_train, T=T, y_vec=y_vec, noise_type=noise_type, uncertainty_type=\"backward\", epsilon=epsilon)\n",
    "        \n",
    "        if misspecify or noise_type == \"group\":\n",
    "            typical_flag = True\n",
    "            \n",
    "        if not typical_flag:\n",
    "            continue\n",
    "            \n",
    "        flipped_labels = flip_labels(y_vec, u_vec)\n",
    "        all_plausible_labels.append(flipped_labels)\n",
    "    \n",
    "    all_plausible_labels = np.array(all_plausible_labels)  # Shape: (k, n)\n",
    "    \n",
    "    # Calculate Actual Mistake as a vector of mean values for each instance\n",
    "    actual_mistakes = np.mean(preds != all_plausible_labels, axis=0)  # Shape: (n,)\n",
    "    \n",
    "\n",
    "    # Calculate Unanticipated Mistake as a vector of mean values for each instance\n",
    "    # Expand preds and yn_train to match dimensions for comparison\n",
    "    preds_expanded = np.expand_dims(preds, axis=0)  # Shape: (1, n)\n",
    "    yn_train_expanded = np.expand_dims(yn_train, axis=0)  # Shape: (1, n)\n",
    "\n",
    "    # Case 1: pred == yn_train but pred != all_plausible_labels\n",
    "    case_1 = (preds_expanded == yn_train_expanded) & (preds_expanded != all_plausible_labels)\n",
    "    \n",
    "    # Case 2: pred != yn_train but pred == all_plausible_labels\n",
    "    case_2 = (preds_expanded != yn_train_expanded) & (preds_expanded == all_plausible_labels)\n",
    "    \n",
    "    # Calculate mean unanticipated mistakes for each instance\n",
    "    unanticipated_mistakes = np.mean(case_1 | case_2, axis=0)  # Shape: (n,)\n",
    "\n",
    "    return actual_mistakes, unanticipated_mistakes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "varying-nightlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2024.49it/s]\n"
     ]
    }
   ],
   "source": [
    "m=1000\n",
    "preds = np.zeros(len(yn_train))\n",
    "a, b = get_uncertainty(m, max_iter, preds, yn_train, p_y_x_dict, noise_type=\"class_independent\", model_type=\"LR\", T=T_true, epsilon=0.25, misspecify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "domestic-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.039, 1.   , 0.048, 1.   , 0.055, 1.   , 1.   , 0.05 , 1.   ,\n",
       "        0.053]),\n",
       " array([0.039, 0.   , 0.048, 0.   , 0.055, 0.   , 0.   , 0.05 , 0.   ,\n",
       "        0.053]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:10], b[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-fruit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisyTS",
   "language": "python",
   "name": "noisyts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
